{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt \n",
    "import seaborn as sns\n",
    "import osmnx as ox\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import folium\n",
    "from prophet import Prophet\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from statistics import mean\n",
    "import matplotlib.dates as mdates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/mariu/Desktop/Masterarbeit/archive/data_start.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     cluster       station  count  cumulative_percentage\n",
      "98         0        WL-012  21208               3.064408\n",
      "4          0         13016  20311               5.999205\n",
      "1          0         13001  19673               8.841816\n",
      "24         0         13430  19155              11.609580\n",
      "3          0         13011  18879              14.337463\n",
      "..       ...           ...    ...                    ...\n",
      "492        3         13379   9595              34.150247\n",
      "607        3  TA1308000029   9431              35.507118\n",
      "600        3  TA1307000124   9096              36.815792\n",
      "472        3         13196   9053              38.118278\n",
      "463        3         13132   7915              39.257037\n",
      "\n",
      "[79 rows x 4 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y8/j3l3spt14jd5q6r19v3l8_800000gn/T/ipykernel_2870/2573352830.py:12: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  station_counts['cumulative_percentage'] = station_counts.groupby('cluster')['count'].apply(lambda x: x.cumsum() / x.sum() * 100)\n",
      "/var/folders/y8/j3l3spt14jd5q6r19v3l8_800000gn/T/ipykernel_2870/2573352830.py:16: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  important_stations = station_counts[station_counts.groupby('cluster')['cumulative_percentage'].apply(lambda x: x <= threshold)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. Datenvorbereitung: Auswahl der relevanten Spalten\n",
    "relevant_columns = ['start_station_id', 'cluster']\n",
    "\n",
    "# 2. Häufigkeitsanalyse\n",
    "# Zählen Sie, wie oft jede Station in jedem Cluster als Start- oder Endstation auftritt\n",
    "station_counts = df[relevant_columns].melt(id_vars=['cluster'], value_name='station').groupby(['cluster', 'station']).size().reset_index(name='count')\n",
    "\n",
    "# Sortieren der Daten für Pareto-Analyse\n",
    "station_counts = station_counts.sort_values(['cluster', 'count'], ascending=[True, False])\n",
    "\n",
    "# 3. Pareto-Analyse: Ermittlung der kumulativen Prozentzahl und Auswahl der wichtigsten Stationen pro Cluster\n",
    "station_counts['cumulative_percentage'] = station_counts.groupby('cluster')['count'].apply(lambda x: x.cumsum() / x.sum() * 100)\n",
    "\n",
    "# Identifizierung der wichtigsten Stationen (z.B. top 20%)\n",
    "threshold = 40\n",
    "important_stations = station_counts[station_counts.groupby('cluster')['cumulative_percentage'].apply(lambda x: x <= threshold)]\n",
    "\n",
    "print(important_stations)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
